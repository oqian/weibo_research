{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e5f4bf",
   "metadata": {},
   "source": [
    "# Table Of Content\n",
    "---\n",
    "\n",
    "1. ### [Data Processing](#data_processing)\n",
    "    1. ### [User Data Processing](#user_data_processing)\n",
    "    3. ### [Post Data Processing](#post_data_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ec5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import *\n",
    "import re\n",
    "from glob import glob\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2cb10",
   "metadata": {},
   "source": [
    "### Input Path Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2dcfcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sean/Desktop/CSC440_project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_dir = os.getcwd()\n",
    "base_path = '/'.join(processing_dir.split('/')[:-1])\n",
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbaf774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sean/Desktop/CSC440_project/data_general'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = base_path + '/data_general'\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebefdb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sean/Desktop/CSC440_project/data_general/tweets'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_path = data_path + '/tweets'\n",
    "posts_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8a55d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sean/Desktop/CSC440_project/data_general/tweets/小黑-9-30/6195560523.csv',\n",
       " '/home/sean/Desktop/CSC440_project/data_general/tweets/瓜果梨桃葡萄橙子/6912965703.csv',\n",
       " '/home/sean/Desktop/CSC440_project/data_general/tweets/鹿家宁浅/3208770254.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path_list = map(lambda x: glob(x + '/*.csv'), glob(posts_path+'/*/'))\n",
    "csv_path_list = filter(lambda x : len(x) > 0, csv_path_list)\n",
    "csv_path_list = list(map(lambda x:x[0], csv_path_list))\n",
    "csv_path_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd606c",
   "metadata": {},
   "source": [
    "### Output Path Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec71ccd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sean/Desktop/CSC440_project/data_general/df'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = data_path + '/df'\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8351f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df_output_path = output_path+'/user_df.pkl'\n",
    "posts_full_df_output_path = output_path+'/post_full_%d.pkl'\n",
    "posts_no_content_df_output_path = output_path+'/post_no_content.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a77e90",
   "metadata": {},
   "source": [
    "<a name=\"data_processing\"/>\n",
    "\n",
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfda46",
   "metadata": {},
   "source": [
    "<a name=\"user_data_processing\"/>\n",
    "\n",
    "## User Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1159cf",
   "metadata": {},
   "source": [
    "### Read Raw users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3846e4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>#tweets</th>\n",
       "      <th>#follower</th>\n",
       "      <th>#following</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6309921628</th>\n",
       "      <td>f</td>\n",
       "      <td>2902</td>\n",
       "      <td>344</td>\n",
       "      <td>403</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007931743</th>\n",
       "      <td>m</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7471743898</th>\n",
       "      <td>m</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>265</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701747600</th>\n",
       "      <td>f</td>\n",
       "      <td>3175</td>\n",
       "      <td>95113</td>\n",
       "      <td>1052</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577162125</th>\n",
       "      <td>m</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gender  #tweets  #follower  #following  verified\n",
       "id                                                         \n",
       "6309921628      f     2902        344         403     False\n",
       "6007931743      m       11         20         163     False\n",
       "7471743898      m        5         10         265     False\n",
       "5701747600      f     3175      95113        1052     False\n",
       "7577162125      m       25          3         190     False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(data_path+'/users.csv')\n",
    "users = users.rename(columns={\n",
    "    '用户id':'id',\n",
    "    '性别': 'gender',\n",
    "    '微博数':'#tweets',\n",
    "    '粉丝数': '#follower',\n",
    "    '关注数': '#following',\n",
    "    '是否认证':'verified'\n",
    "})\n",
    "users = users[['id','gender','#tweets','#follower','#following','verified']]\n",
    "users.drop_duplicates('id',inplace=True)\n",
    "users.set_index('id', inplace=True)\n",
    "def to_int_follower_count(follower_count_str):\n",
    "    if type(follower_count_str) is int:\n",
    "        return follower_count_str\n",
    "    if '万' in follower_count_str:\n",
    "        return int(float(follower_count_str[:-1])*10000)\n",
    "    if '亿' in follower_count_str:\n",
    "        return int(float(follower_count_str[:-1])*100000000)\n",
    "    else:\n",
    "        return int(follower_count_str)\n",
    "users['#follower'] = users['#follower'].map(to_int_follower_count)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5fa95",
   "metadata": {},
   "source": [
    "### Read locations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba64039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5711341129</th>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7412051152</th>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568601498</th>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804028250</th>\n",
       "      <td>广东 广州</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7448767160</th>\n",
       "      <td>四川</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           location\n",
       "id                 \n",
       "5711341129       其他\n",
       "7412051152       其他\n",
       "7568601498       其他\n",
       "1804028250    广东 广州\n",
       "7448767160       四川"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = pd.read_csv(data_path + '/locations_combined.csv', header = None, names = ['id','location'])\n",
    "locations.drop_duplicates('id',inplace=True)\n",
    "locations.set_index('id', inplace=True)\n",
    "locations.astype({\n",
    "    'location' : 'string'\n",
    "}, copy = False)\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45435674",
   "metadata": {},
   "source": [
    "### Merge Users and Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f671e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>#tweets</th>\n",
       "      <th>#follower</th>\n",
       "      <th>#following</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6309921628</td>\n",
       "      <td>f</td>\n",
       "      <td>2902</td>\n",
       "      <td>344</td>\n",
       "      <td>403</td>\n",
       "      <td>False</td>\n",
       "      <td>河南 许昌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6007931743</td>\n",
       "      <td>m</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>江苏 南京</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7471743898</td>\n",
       "      <td>m</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>265</td>\n",
       "      <td>False</td>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5701747600</td>\n",
       "      <td>f</td>\n",
       "      <td>3175</td>\n",
       "      <td>95113</td>\n",
       "      <td>1052</td>\n",
       "      <td>False</td>\n",
       "      <td>上海 杨浦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7577162125</td>\n",
       "      <td>m</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>False</td>\n",
       "      <td>山东 济南</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id gender  #tweets  #follower  #following  verified location\n",
       "0  6309921628      f     2902        344         403     False    河南 许昌\n",
       "1  6007931743      m       11         20         163     False    江苏 南京\n",
       "2  7471743898      m        5         10         265     False       其他\n",
       "3  5701747600      f     3175      95113        1052     False    上海 杨浦\n",
       "4  7577162125      m       25          3         190     False    山东 济南"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = users.merge(locations, left_index=True, right_index=True, how='inner')\n",
    "users = users.reset_index()\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f76563",
   "metadata": {},
   "source": [
    "### Remove users without collected content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f4d8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>#tweets</th>\n",
       "      <th>#follower</th>\n",
       "      <th>#following</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6309921628</td>\n",
       "      <td>f</td>\n",
       "      <td>2902</td>\n",
       "      <td>344</td>\n",
       "      <td>403</td>\n",
       "      <td>False</td>\n",
       "      <td>河南 许昌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6007931743</td>\n",
       "      <td>m</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>江苏 南京</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7471743898</td>\n",
       "      <td>m</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>265</td>\n",
       "      <td>False</td>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5701747600</td>\n",
       "      <td>f</td>\n",
       "      <td>3175</td>\n",
       "      <td>95113</td>\n",
       "      <td>1052</td>\n",
       "      <td>False</td>\n",
       "      <td>上海 杨浦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7577162125</td>\n",
       "      <td>m</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>False</td>\n",
       "      <td>山东 济南</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id gender  #tweets  #follower  #following  verified location\n",
       "0  6309921628      f     2902        344         403     False    河南 许昌\n",
       "1  6007931743      m       11         20         163     False    江苏 南京\n",
       "2  7471743898      m        5         10         265     False       其他\n",
       "3  5701747600      f     3175      95113        1052     False    上海 杨浦\n",
       "4  7577162125      m       25          3         190     False    山东 济南"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids_with_content = set(map(lambda x: int(x.rsplit('/',maxsplit=1)[1].strip('.csv')), csv_path_list))\n",
    "users_with_content = users[users['id'].isin(user_ids_with_content)]\n",
    "del user_ids_with_content\n",
    "users_with_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64334f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             int64\n",
       "gender        string\n",
       "#tweets        int64\n",
       "#follower      int64\n",
       "#following     int64\n",
       "verified        bool\n",
       "location      string\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_with_content = users_with_content.astype(\n",
    "    {\n",
    "        'location': 'string',\n",
    "        'id': 'int64',\n",
    "        'gender': 'string'\n",
    "    }\n",
    ")\n",
    "users_with_content.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c37051",
   "metadata": {},
   "source": [
    "### Get Censored & Number of Collected Posts for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20754bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "censor_indications = [\n",
    "    '抱歉，由于作者设置，',\n",
    "    '该微博因被多人投诉',\n",
    "    '该账号因被投诉违反',\n",
    "    '该账号因被投诉',\n",
    "    '查看帮助： 网页链接'\n",
    "]\n",
    "\n",
    "rename_needed_dict = {\n",
    "    '视频url': 'reposter_device',  \n",
    "    '原始图片url': 'reposting_time', \n",
    "    '位置': '#likes', \n",
    "    '日期': '#comments', \n",
    "    '工具': '#reposts', \n",
    "    '点赞数': 'repost_weibo_comment',\n",
    "    '源用户id': 'source_user_id', \n",
    "    '源用户昵称': 'source_user_nickname', \n",
    "    '源微博原始图片url': 'source_weibo_post_time',\n",
    "    '源微博视频url': 'source_weibo_device', \n",
    "    '源微博位置': '#source_weibo_likes', \n",
    "    '源微博日期': '#source_weibo_comments', \n",
    "    '源微博工具': '#source_weibo_reposts', \n",
    "    '源微博点赞数': 'source_weibo_content' \n",
    "}\n",
    "\n",
    "rename_no_need_dict = {\n",
    "    \"正文\": 'repost_weibo_comment',\n",
    "    '日期': 'reposting_time',\n",
    "    '工具': 'reposter_device',\n",
    "    '点赞数': '#likes',\n",
    "    '评论数':'#comments',\n",
    "    '转发数': '#reposts',\n",
    "    '源用户id': 'source_user_id',\n",
    "    '源用户昵称': 'source_user_nickname',\n",
    "    '源微博正文': 'source_weibo_content',\n",
    "    '源微博日期': 'source_weibo_post_time',\n",
    "    '源微博工具': 'source_weibo_device',\n",
    "    '源微博点赞数': '#source_weibo_likes',\n",
    "    '源微博评论数': '#source_weibo_comments',\n",
    "    '源微博转发数': '#source_weibo_reposts'\n",
    "}\n",
    "\n",
    "keep_columns = rename_no_need_dict.values()\n",
    "\n",
    "def reorg_column_names(user_weibo_df):\n",
    "    # need to iterate by row and then check each row \n",
    "    # create 2 dataframes, one holding non-change, other holding change, then merge\n",
    "    df_no_change = []\n",
    "    df_w_change = []\n",
    "#     user_weibo_df = user_weibo_df.astype({\n",
    "#         '日期': 'string'\n",
    "#     })\n",
    "    for _, row in user_weibo_df.iterrows():\n",
    "        try:\n",
    "            datetime.strptime(str(row['源微博原始图片url']),'%a %b %d %X %z %Y')\n",
    "            df_w_change.append(row)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                datetime.strptime(str(row['日期']),'%a %b %d %X %z %Y')\n",
    "                df_no_change.append(row)\n",
    "            except ValueError:\n",
    "                # the column cannot be parsed so it will be dropped\n",
    "                pass\n",
    "            \n",
    "    if df_no_change:\n",
    "        df_no_change = pd.DataFrame(df_no_change).rename(columns=rename_no_need_dict)[keep_columns]\n",
    "    if df_w_change:\n",
    "        df_w_change = pd.DataFrame(df_w_change).rename(columns=rename_needed_dict)[keep_columns]\n",
    "    return pd.concat([pd.DataFrame(df_no_change),pd.DataFrame(df_w_change)]).astype(\n",
    "        {\n",
    "            \"repost_weibo_comment\":\"string\",\n",
    "            \"reposting_time\":\"string\",\n",
    "            \"reposter_device\":\"string\",\n",
    "            \"#likes\":\"int64\",\n",
    "            \"#comments\":\"int64\",\n",
    "            \"#reposts\":\"int64\",\n",
    "            \"source_user_id\":\"float64\",\n",
    "            \"source_user_nickname\":\"string\",\n",
    "            \"source_weibo_content\":\"string\",\n",
    "            \"source_weibo_post_time\":\"string\",\n",
    "            \"source_weibo_device\":\"string\",\n",
    "            \"#source_weibo_likes\":\"int64\",\n",
    "            \"#source_weibo_comments\":\"int64\",\n",
    "            \"#source_weibo_reposts\":\"int64\",  \n",
    "        },\n",
    "        copy=False\n",
    "    )\n",
    "\n",
    "# reorg_column_names(pd.read_csv('/home/sean/Desktop/CSC440_project/data_general/tweets/JadeRing-玉儿/5797519917.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba881751",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_num = 8 # Should be number of real CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bebb1d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52770it [06:38, 129.95it/s]"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Lock\n",
    "from functools import reduce\n",
    "\n",
    "with tqdm() as bar:\n",
    "    lock = Lock()\n",
    "    def calculate_post_stats(csv_path_list):\n",
    "        censored_vs_collected_post_num = {}\n",
    "        for csv_path in csv_path_list:\n",
    "            \n",
    "            user_id = int(csv_path.split('/')[-1].strip('.csv'))\n",
    "            user_weibo_df = reorg_column_names(pd.read_csv(csv_path))\n",
    "            \n",
    "            \n",
    "            censored_vs_collected_post_num[user_id] = (\n",
    "                sum(user_weibo_df['source_weibo_content'].map(lambda content: any((keyword in str(content) for keyword in censor_indications)))),\n",
    "                len(user_weibo_df)\n",
    "            )\n",
    "            with lock:\n",
    "                bar.update()\n",
    "        return censored_vs_collected_post_num\n",
    "    \n",
    "    with Pool(pool_num) as p:\n",
    "        csv_sections = np.array_split(csv_path_list, pool_num)\n",
    "        censored_vs_collected_post_num_list = p.map(calculate_post_stats, csv_sections)\n",
    "        censored_vs_collected_post_num = reduce(lambda a,b: a | b, censored_vs_collected_post_num_list)\n",
    "\n",
    "len(censored_vs_collected_post_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_content['#censored_posts'] = users_with_content['id'].map(\n",
    "    lambda id: censored_vs_collected_post_num[id][0] if id in censored_vs_collected_post_num else 0\n",
    ")\n",
    "\n",
    "users_with_content['#collected_posts'] = users_with_content['id'].map(\n",
    "    lambda id: censored_vs_collected_post_num[id][1] if id in censored_vs_collected_post_num else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed461575",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"censored post = \",sum([a for a,_ in censored_vs_collected_post_num.values()]))\n",
    "print(\"all post = \",sum([b for _,b in censored_vs_collected_post_num.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60faf54e",
   "metadata": {},
   "source": [
    "<a name=\"follower_count_percentile\"/>\n",
    "\n",
    "### Follower Count Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_content.sort_values('#follower', inplace=True)\n",
    "df_len = len(users_with_content)\n",
    "\n",
    "lesser_num = 0\n",
    "cur_follower_num = 0\n",
    "cur_count = 0\n",
    "percentiles = deque()\n",
    "\n",
    "for follower_num in users_with_content['#follower']:\n",
    "    if follower_num == cur_follower_num:\n",
    "        cur_count += 1\n",
    "    else:\n",
    "        percentile = (lesser_num) / df_len * 100\n",
    "        percentiles.extend([percentile for _ in range(cur_count)])\n",
    "        cur_follower_num = follower_num\n",
    "        lesser_num += cur_count \n",
    "        cur_count = 1\n",
    "\n",
    "percentile = (lesser_num) / df_len * 100\n",
    "percentiles.extend([percentile for _ in range(cur_count)])\n",
    "\n",
    "users_with_content[\"#follower_percentile_grouped\"] = list(map(lambda x: x//10 + 1, percentiles))\n",
    "users_with_content[\"#follower_percentile_grouped\"] = users_with_content[\"#follower_percentile_grouped\"].astype('int32')\n",
    "users_with_content.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342c456",
   "metadata": {},
   "source": [
    "<a name=\"location_to_province\"/>\n",
    "\n",
    "### Location to Province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_prefixes = {\"昵称\", \"认证\"}\n",
    "\n",
    "def to_province(location):\n",
    "    location = location.split(' ')[0]\n",
    "    return location if all((matcher not in location for matcher in weird_prefixes)) else '其他'\n",
    "users_with_content['province'] = users_with_content['location'].map(to_province).astype('string')\n",
    "users_with_content['province']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd244ff4",
   "metadata": {},
   "source": [
    "### Province GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d83c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "gdp_by_province = defaultdict(int) # default value for GDP is 0\n",
    "\n",
    "gdp_by_province.update({\n",
    "    \"北京\":23805,\n",
    "    \"上海\":23277,\n",
    "    \"江苏\":17121,\n",
    "    \"浙江\":16358,\n",
    "    \"福建\":15531,\n",
    "    \"广东\":14223,\n",
    "    \"天津\":13569,\n",
    "    \"湖北\":10988,\n",
    "    \"重庆\":10867,\n",
    "    \"山东\":10811,\n",
    "    \"内蒙古\":9977,\n",
    "    \"陕西\":9239,\n",
    "    \"安徽\":8703,\n",
    "    \"湖南\":8681,\n",
    "    \"辽宁\":8667,\n",
    "    \"海南\":8323,\n",
    "    \"河南\":8302,\n",
    "    \"四川\":8229,\n",
    "    \"新疆\":7721,\n",
    "    \"宁夏\":7686,\n",
    "    \"江西\":7682,\n",
    "    \"青海\":6998,\n",
    "    \"西藏\":6997,\n",
    "    \"云南\":6950,\n",
    "    \"贵州\":6828,\n",
    "    \"河北\":6797,\n",
    "    \"山西\":6735,\n",
    "    \"吉林\":6577,\n",
    "    \"广西\":6386,\n",
    "    \"黑龙江\":5129,\n",
    "    \"甘肃\":4624,\n",
    "    \"香港\":46700,\n",
    "    \"台湾\":28306,\n",
    "    \"澳门\":38769,\n",
    "})\n",
    "\n",
    "users_with_content['province_gdp'] = users_with_content['province'].map(lambda p: gdp_by_province[p])\n",
    "users_with_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077472a4",
   "metadata": {},
   "source": [
    "### Censored Ratio & renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_content = users_with_content.rename(columns={\n",
    "    'verified':\"verification\"\n",
    "})\n",
    "users_with_content['censored'] = users_with_content['#censored_posts'].map(lambda x: x > 0)\n",
    "users_with_content['censored_ratio'] = users_with_content['#censored_posts']/users_with_content['#collected_posts']\n",
    "users_with_content['censored_ratio'] = users_with_content['censored_ratio'].map(lambda x: x if x != float('inf') else 0)\n",
    "users_with_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feaa1dd",
   "metadata": {},
   "source": [
    "### Censored Ratio Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored_users = users_with_content[users_with_content['censored']].copy()\n",
    "uncensored_users = users_with_content[np.logical_not(users_with_content['censored'])].copy()\n",
    "\n",
    "censored_users['censored_ratio_percentile'] = pd.qcut(censored_users['censored_ratio'],3,labels=[1,2,3])\n",
    "uncensored_users['censored_ratio_percentile'] = 0\n",
    "\n",
    "users_with_content = pd.concat([uncensored_users, censored_users])\n",
    "\n",
    "del censored_users\n",
    "del uncensored_users\n",
    "users_with_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2956b",
   "metadata": {},
   "source": [
    "### Unused Fields Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11810b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_content.drop([\n",
    "    'content',\n",
    "    'location'\n",
    "], axis = 'columns', inplace=True, errors='ignore')\n",
    "users_with_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(users_df_output_path, 'wb') as f:\n",
    "    pickle.dump(users_with_content, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64884a4a",
   "metadata": {},
   "source": [
    "### Loading data (Run only when needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(users_df_output_path, 'rb') as f:\n",
    "#     users_with_content = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a8a50",
   "metadata": {},
   "source": [
    "<a name=\"post_data_processing\"/>\n",
    "\n",
    "## Post Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b431d1a8",
   "metadata": {},
   "source": [
    "### Concat user csv's to a single df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e335ee3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def concat_user_csvs_to_df(csv_list, bar=None, lock=None):\n",
    "    censored_repost_list = deque()\n",
    "    user_csv_df_list = []\n",
    "    for csv_path in csv_list:        \n",
    "        user_weibo_df = pd.read_csv(csv_path)\n",
    "        user_weibo_df = reorg_column_names(user_weibo_df)\n",
    "        user_weibo_df['user_id'] = int(csv_path.split('/')[-1].strip('.csv'))\n",
    "        user_csv_df_list.append(user_weibo_df)\n",
    "        if bar is not None and lock is not None:\n",
    "            with lock:\n",
    "                bar.update()\n",
    "    \n",
    "    return pd.concat(user_csv_df_list).astype({\n",
    "            'reposting_time': 'string',\n",
    "            'reposter_device': 'string',\n",
    "            'repost_weibo_comment': 'string',\n",
    "            'source_weibo_post_time': 'string',\n",
    "            'source_weibo_content': 'string',\n",
    "            'source_user_nickname': 'string',\n",
    "            'source_weibo_device': 'string'\n",
    "        }, copy=False)\n",
    "\n",
    "concat_user_csvs_to_df(csv_path_list[:2]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04f33b",
   "metadata": {},
   "source": [
    "### Device Transform Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222386f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_mapping = {\n",
    "    'Apple':['iPhone','iPad','Mac'],\n",
    "    'Web':['浏览器', '微博'],\n",
    "    'Huawei':['Huawei','nova','华为','HUAWEI','nova','Harmony'],\n",
    "    'Honor':['荣耀'],\n",
    "    'XiaoMi':['小米', 'Redmi','红米'],\n",
    "    'vivo':['vivo'],\n",
    "    'OPPO':['OPPO'],\n",
    "    'Samsung':['三星','Samsung'],\n",
    "    'General Andoid':['android','Android'],\n",
    "    'Realme':['realme','真我'],\n",
    "    'IQOO':['iQOO'],\n",
    "    'OnePlus':['一加','OnePlus']\n",
    "}\n",
    "\n",
    "def get_reposter_device(df):   \n",
    "    def to_brand(client_name):\n",
    "        if type(client_name) is not str:\n",
    "            return 'NaN'\n",
    "        for brand, devices in device_mapping.items():\n",
    "            if any((device in client_name for device in devices)):\n",
    "                return brand\n",
    "        return 'other'\n",
    "    \n",
    "    return df['reposter_device'].map(to_brand).astype('string')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32dba9",
   "metadata": {},
   "source": [
    "### Censored Transform Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_censored(series):\n",
    "    return series.map(lambda content: any((keyword in str(content) for keyword in censor_indications)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0bb72",
   "metadata": {},
   "source": [
    "### Time Transform Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_timestamp(df, col_name):\n",
    "    def to_timestamp(s):\n",
    "        if type(s) is not str:\n",
    "            return None\n",
    "        try:\n",
    "            return datetime.fromtimestamp(datetime.strptime(s, '%a %b %d %X %z %Y').timestamp()).strftime(\"%Y-%m\")\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return df[col_name].map(to_timestamp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5f35b",
   "metadata": {},
   "source": [
    "### User Information Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a14bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = users_with_content.copy()\n",
    "users_df = users_df.set_index('id')\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e9e49",
   "metadata": {},
   "source": [
    "### Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaea7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_post_full_df(df):\n",
    "    df = df.assign(\n",
    "        general_device = get_reposter_device(df),\n",
    "        repost_timestamp_month = get_timestamp(df, 'reposting_time'),\n",
    "        post_timestamp_month = get_timestamp(df, 'source_weibo_post_time'),\n",
    "        post_censored = get_censored(df['source_weibo_content'])\n",
    "    )\n",
    "    df.drop([\n",
    "        \"source_user_nickname\",\n",
    "        \"source_user_id\",\n",
    "        \"reposter_device\",\n",
    "        \"source_weibo_device\",\n",
    "        \"reposting_time\",\n",
    "        \"source_weibo_post_time\",\n",
    "        \"#likes\",\n",
    "        \"#comments\",\n",
    "        \"#reposts\",\n",
    "        \"#source_weibo_likes\",\n",
    "        \"#source_weibo_comments\",\n",
    "        \"#source_weibo_reposts\"\n",
    "    ], axis = 'columns', inplace=True)\n",
    "    return df.merge(users_df, left_on='user_id', right_on='id', right_index=True, suffixes=('_post', '_user'))\n",
    "\n",
    "to_post_full_df(concat_user_csvs_to_df(csv_path_list[:100])).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_post_no_content_df(post_full_df):\n",
    "    post_full_df.drop([\n",
    "        \"repost_weibo_comment\",\n",
    "        \"source_weibo_content\"\n",
    "    ], axis = 'columns', inplace=True)\n",
    "    return post_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dfs = 12\n",
    "cpu_num = 8\n",
    "csv_path_sections = np.array_split(csv_path_list, num_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c2ce7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transform Begin\n",
    "no_content_post_dfs = []\n",
    "\n",
    "for partition_id, csv_list_sub_section in enumerate(np.array_split(csv_path_list, num_dfs)):\n",
    "    print('partition %d'%partition_id)\n",
    "    csv_list_sub_section_tasks = np.array_split(csv_list_sub_section, cpu_num*10) # arbitrary number to show progress\n",
    "    with Pool(cpu_num) as p:\n",
    "        dfs = p.map(concat_user_csvs_to_df, tqdm(csv_list_sub_section_tasks, desc=\"csv to df\"))\n",
    "\n",
    "        dfs = p.map(to_post_full_df, tqdm(dfs, desc=\"df to full post df\"))\n",
    "        with open(posts_full_df_output_path % partition_id, 'wb') as f:\n",
    "            pickle.dump(pd.concat(dfs), f)\n",
    "\n",
    "        dfs = p.map(to_post_no_content_df, tqdm(dfs, desc=\"full post df to no content df\"))\n",
    "        no_content_post_dfs.append(pd.concat(dfs))\n",
    "\n",
    "with open(posts_no_content_df_output_path, 'wb') as f:\n",
    "    pickle.dump(pd.concat(no_content_post_dfs), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba881f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
